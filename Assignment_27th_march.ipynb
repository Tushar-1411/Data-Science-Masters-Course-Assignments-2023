{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20322a2-3dc2-414a-8385-47b905d5dbc8",
   "metadata": {},
   "source": [
    "### question 1\n",
    "\n",
    "R squared is a performance metrics which is used to evluate the accuracy of regression models.\n",
    "\n",
    "Formula for R-Squared:  1 - (Sum of Squares of residuals / Sum of squares of Total)\n",
    "\n",
    "It represents the error rate of our model that how much our model has succesfully predicted correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b134acc-bdf1-416f-b027-9c83aa4ac0ae",
   "metadata": {},
   "source": [
    "### question 2\n",
    "\n",
    "Adjusted R-Squared is also a performance metrics for regression models.\n",
    "\n",
    "It differs from the R-squared in the fact that when more features are added the overall accuracy of the model increases regardless of the dependence of the feature and target variable. Adjusted R-squared accounts for this problem which R-squared dosen't."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6a8979-b67d-4141-a73e-f05553e5824e",
   "metadata": {},
   "source": [
    "### question 3\n",
    "\n",
    "Adjusted R-squared can be used when the number of features are high with low interdependece with target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d71809-10a4-4b64-b983-e492a90cd4cf",
   "metadata": {},
   "source": [
    "### question 4\n",
    "\n",
    "1. RMSE (Root mean squared error) : Its the square root of the sum of the squares of the difference between the actual values and the predicted values.\n",
    "\n",
    "Formula : sqrt(sum ( sqaures (actual - predicted ) ))\n",
    "\n",
    "2. MSE (Mean Squared Error) : Its the sum of squares of difference of actual and predicted values.\n",
    "\n",
    "Formula : sum ( sqaures (actual - predicted ) )\n",
    "\n",
    "3. MAE (Mean Absolute Error) : Its the sum of the absolute difference of actual and predicted values.\n",
    "\n",
    "Formula : sum ( abs (actual - predicted) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b0f0a7-ae5d-43ef-8c31-02686ae29d8a",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "1. RMSE is the square root of the MSE. By square rooting the MSE, we return the error metric to the same unit as the target variable, which can often make it easier to interpret. RMSE is better in terms of reflecting performance when dealing with large error values.\n",
    "\n",
    "2. MSE is highly biased for higher values. It is sensitive to outliers, meaning that even a single large error can significantly increase the value of the MSE.\n",
    "\n",
    "3. MAE is less biased for higher values and is more robust to outliers than MSE. However, it may not adequately reflect the performance when dealing with large error values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68ea3e7-800d-4217-a10f-37a27267c2d1",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) is a regression analysis method that performs both variable selection and regularization in order to enhance the prediction accuracy and interpretability of the resulting statistical model. It works by adding a penalty term to the loss function, which is equivalent to the absolute value of the magnitude of coefficients. This forces certain coefficients to become zero, effectively excluding them from the model.\n",
    "\n",
    "Ridge regularization, on the other hand, adds a penalty term equivalent to the square of the magnitude of coefficients4. This shrinks the size of the coefficients but does not set them to zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24789be7-11c8-410d-a3fd-e398565074c5",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Regularization is a technique used to prevent overfitting in machine learning models by adding a penalty term to the loss function. This penalty term restricts the modelâ€™s complexity by shrinking the coefficient estimates towards zero. When a model suffers from overfitting, it means that it has learned the training data too well, including the noise and random fluctuations in the data. As a result, the model performs poorly on new, unseen data.\n",
    "\n",
    "An example of how regularization can help prevent overfitting is in linear regression. In linear regression, we try to find the best line that fits the data by minimizing the residual sum of squares (RSS). However, if we have many features, some of which may be correlated, the model can become too complex and overfit the data. By adding a penalty term to the RSS, we can control the complexity of the model and prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8079a0-c8bd-471f-96a9-1c37b25e06c0",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Regularized linear models, such as Lasso and Ridge regression, are powerful tools for regression analysis, but they do have some limitations. Here are some of the limitations of regularized linear models:\n",
    "\n",
    "- **Assumption of linearity**\n",
    "\n",
    "- **Sensitivity to scale**\n",
    "\n",
    "- **Choice of regularization parameter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3244d2fc-a77c-4e34-bec7-e2fc825e1a49",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "It is not possible to directly compare the performance of two models using different evaluation metrics, such as RMSE and MAE. RMSE and MAE measure different aspects of model performance and have different units, so a direct comparison between the two is not meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f3f367-6ec8-458d-bb1c-93a3efb8106d",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "It is not possible to determine which model is the better performer based solely on the type of regularization and the value of the regularization parameter. The performance of a regularized linear model depends on many factors, including the choice of regularization method, the value of the regularization parameter, the characteristics of the data, and the specific problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b509304-12cc-41c2-ba30-775023bf8d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
