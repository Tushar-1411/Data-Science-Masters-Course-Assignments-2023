{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c5d5b95-307a-42d4-9ee1-b896455c4fd1",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "- Decision Tree Classifier is a supervised machine learning algorithm used for both classification and regression tasks.\n",
    "- It works by recursively splitting the dataset into subsets based on the most significant attribute at each step.\n",
    "- The goal is to create a tree-like structure where each internal node represents a decision based on an attribute, and each leaf node represents a class label or a regression value.\n",
    "- To make predictions, you start at the root node and traverse down the tree following the decision rules until you reach a leaf node, which provides the predicted class or value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b944b93c-aa45-4901-bab3-ef7922462c16",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "- Decision tree classification uses metrics like Gini impurity or entropy to evaluate the purity of a dataset.\n",
    "- At each node, the algorithm selects the attribute that minimizes the impurity of the child nodes.\n",
    "- The Gini impurity for a node is calculated as:\n",
    "\n",
    "Gini(node) = 1 - Î£(p_i^2) for all classes, where p_i is the proportion of samples of class i in the node.\n",
    "\n",
    "- The attribute with the highest information gain (reduction in impurity) is chosen for the split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f1c62e-f019-4f73-9185-e14999fa5ab6",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "- In binary classification, the decision tree starts with a root node and splits the data into two subsets.\n",
    "- Each split is based on an attribute and a threshold value.\n",
    "- The leaf nodes represent the two classes, e.g., \"Yes\" and \"No,\" \"1\" and \"0,\" or \"Positive\" and \"Negative.\"\n",
    "- As you traverse down the tree, you compare the attribute value of the sample with the threshold at each node to decide which branch to follow until you reach a leaf node, which determines the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0267b-f572-4b65-8a56-ba7742affa5c",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "- Geometrically, decision tree classification creates axis-aligned decision boundaries.\n",
    "- At each split, it selects one feature and a threshold, creating a boundary parallel to one of the coordinate axes.\n",
    "- Decision boundaries are perpendicular to the feature axes, which leads to rectangular regions in the feature space.\n",
    "- Predictions are made by determining which region a new data point falls into based on the feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c3770-1090-4d26-ae3a-1bbc93d943dc",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "A confusion matrix is a table that compares the actual labels of a dataset with the predicted labels produced by a classification model.\n",
    "It has four components:\n",
    "- True Positive (TP): Correctly predicted positive instances.\n",
    "- True Negative (TN): Correctly predicted negative instances.\n",
    "- False Positive (FP): Incorrectly predicted positive instances (Type I error).\n",
    "- False Negative (FN): Incorrectly predicted negative instances (Type II error).\n",
    "\n",
    "\n",
    "The confusion matrix helps in calculating various evaluation metrics like accuracy, precision, recall, and F1-score, which provide insights into the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8343696-1041-4125-a9fe-a452060ef2c5",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "                     Actual Positive   Actual Negative\n",
    "Predicted Positive ------------  TP  ---------------- FP\n",
    "\n",
    "Predicted Negative ------------  FN  ---------------  TN\n",
    "\n",
    "- Precision measures the accuracy of positive predictions:\n",
    "\n",
    "Precision = TP / (TP + FP)\n",
    "\n",
    "- Recall measures the ability to capture all positive instances:\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "- F1 Score balances precision and recall:\n",
    "\n",
    "F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670ed899-dd06-4d89-9ec1-0ffaf7b96435",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "The choice of evaluation metric depends on the specific goals and requirements of your classification problem.\n",
    "- Accuracy is commonly used but can be misleading in imbalanced datasets.\n",
    "- Precision is vital when false positives are costly (e.g., medical diagnosis).\n",
    "- Recall is crucial when false negatives are costly (e.g., detecting fraud).\n",
    "- F1 Score balances precision and recall, useful when there's an uneven class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a78bf0b-d86b-43ba-afb8-d73b8a32da34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Question 8\n",
    "\n",
    "Consider a spam email filter:\n",
    "- High precision is crucial because classifying a legitimate email as spam (false positive) can be highly frustrating for users.\n",
    "- Users want to minimize the number of non-spam emails in their spam folder.\n",
    "- Precision is the key metric to ensure that emails classified as spam are indeed spam, reducing false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48e9d4-ac9e-4e4f-a8d4-9631d4251085",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Consider a medical test for a severe disease:\n",
    "- High recall is essential because failing to detect the disease (false negative) can be life-threatening.\n",
    "- A false negative result might lead to delayed treatment.\n",
    "- Recall is the key metric to ensure that as many true positive cases are identified as possible, reducing false negatives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
