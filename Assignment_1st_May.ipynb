{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18a6042a-79c6-46d2-94fd-860acfde166c",
   "metadata": {},
   "source": [
    "1. **Contingency Matrix:**\n",
    "   - A contingency matrix, also known as a confusion matrix, is a table used in classification to evaluate the performance of a model. It compares predicted and actual classes, breaking down the results into true positives, true negatives, false positives, and false negatives.\n",
    "\n",
    "2. **Pair Confusion Matrix:**\n",
    "   - A pair confusion matrix is a specific type of confusion matrix that focuses on pairwise classification. It is particularly useful when dealing with multi-class classification problems with imbalanced classes, allowing a more detailed analysis of the model's performance.\n",
    "\n",
    "3. **Extrinsic Measure in NLP:**\n",
    "   - In NLP, an extrinsic measure assesses the performance of a language model based on its contribution to a specific task or application. For example, evaluating a sentiment analysis model based on its impact on improving customer satisfaction.\n",
    "\n",
    "4. **Intrinsic Measure:**\n",
    "   - An intrinsic measure evaluates the performance of a model based on its internal characteristics, without considering its impact on a specific task. In contrast to extrinsic measures, intrinsic measures focus on model properties like convergence speed, complexity, or interpretability.\n",
    "\n",
    "5. **Purpose of a Confusion Matrix:**\n",
    "   - The confusion matrix helps identify the strengths and weaknesses of a classification model. It provides insights into the types of errors the model is making, such as misclassifying certain classes, and guides improvements.\n",
    "\n",
    "6. **Intrinsic Measures for Unsupervised Learning:**\n",
    "   - Common intrinsic measures include cohesion, separation, and silhouette score for clustering algorithms. These metrics assess how well-clustered the data points are within their clusters and how distinct clusters are from each other.\n",
    "\n",
    "7. **Limitations of Accuracy:**\n",
    "   - Accuracy alone might not be sufficient for evaluating classification tasks, especially in imbalanced datasets. It doesn't account for false positives and false negatives adequately. Precision, recall, F1 score, or area under the ROC curve (AUC-ROC) are often used in conjunction with accuracy to provide a more comprehensive evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5219d-389b-41f7-8c82-4403b02353d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
