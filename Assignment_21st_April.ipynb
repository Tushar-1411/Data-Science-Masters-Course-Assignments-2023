{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61eb2323-f66f-4e56-95f7-52fd2e21cad8",
   "metadata": {},
   "source": [
    "**Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?**\n",
    "\n",
    "- *Euclidean Distance:* Measures the straight-line distance between two points in space.\n",
    "  \n",
    "- *Manhattan Distance:* Measures the sum of the absolute differences between the coordinates.\n",
    "\n",
    "The main difference is in the path the distance takes. Euclidean is the shortest distance, while Manhattan is like moving through city blocks. The choice can affect the sensitivity to outliers and the nature of the data.\n",
    "\n",
    "**Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be used to determine the optimal k value?**\n",
    "\n",
    "The optimal value of k is usually determined using techniques like cross-validation. You can perform a grid search over a range of k values and select the one that gives the best performance on a validation set. Techniques like k-fold cross-validation help in robustly estimating performance.\n",
    "\n",
    "**Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In what situations might you choose one distance metric over the other?**\n",
    "\n",
    "- *Euclidean:* Suitable when features are continuous and follow a normal distribution.\n",
    "  \n",
    "- *Manhattan:* Robust to outliers, works well with non-normally distributed data.\n",
    "\n",
    "The choice depends on the nature of the data and the problem at hand.\n",
    "\n",
    "**Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect the performance of the model? How might you go about tuning these hyperparameters to improve model performance?**\n",
    "\n",
    "Common hyperparameters include k, the choice of distance metric, and the method used to break ties. Tuning involves trying different values for these hyperparameters and evaluating performance. Grid search or random search can be employed for efficient tuning.\n",
    "\n",
    "**Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What techniques can be used to optimize the size of the training set?**\n",
    "\n",
    "With a small training set, the model might be sensitive to noise. As the training set size increases, the model becomes more robust. Techniques like cross-validation can be used to find an optimal training set size.\n",
    "\n",
    "**Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you overcome these drawbacks to improve the performance of the model?**\n",
    "\n",
    "Drawbacks include sensitivity to irrelevant features, outliers, and high computational cost for large datasets. Feature engineering, outlier detection/handling, and dimensionality reduction can be used to mitigate these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44410ccb-b5f1-4952-8339-fb4480483e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
