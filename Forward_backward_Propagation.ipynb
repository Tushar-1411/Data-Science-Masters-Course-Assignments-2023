{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7980fb-c441-4f38-bff0-4aff6c0cab4c",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "The main purpose of the forward propagation is to :\n",
    "1. Initialize weights and biases\n",
    "2. Calculate the predicted value based on weights and biases\n",
    "3. Calculate the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd28a6-aa12-4324-b92c-68e31f7d1a10",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Consider a network with two input features x1 and x2, weights w1 and w2, and bias b. The activation function is the sigmoid function (σ(z)).\n",
    "\n",
    "Input vector: X = [x1, x2], \n",
    "Weight vector: W = [w1, w2], \n",
    "Bias: b\n",
    "\n",
    "The weighted sum z would be:\n",
    "\n",
    "z = w1 * x1 + w2 * x2 + b\n",
    "\n",
    "The output y would be:\n",
    "\n",
    "y = σ(z) = σ(w1 * x1 + w2 * x2 + b)\n",
    "\n",
    "This represents the single neuron's activation based on the weighted combination of the input features and the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364499ee-ff64-4a9c-a130-2d0fdf2fb22d",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Activation functions are mathematical functions applied to the weighted sum (also called linear combination or pre-activation) of inputs in each neuron during forward propagation.\n",
    "These functions introduce non-linearity into the network's output, allowing it to model more intricate relationships between inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506d394-7be0-4406-8e11-4021747e6dca",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Weights (W): These represent the strength of the connections between an input feature and a neuron. During the weighted sum calculation, a higher weight on a particular feature indicates a stronger influence on the neuron's activation. Weights are initially assigned random values and then adjusted through training using backpropagation.\n",
    "\n",
    "Bias (b): This adds a constant value to the weighted sum of inputs. It allows the neuron to shift its activation function \"up\" or \"down\" independently of the input values, providing more flexibility in modeling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38fb78a-8df6-43ba-8b3b-bd469265c510",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Purpose of softmax function is to calculate the probabilites of the outputs belonging to a specific class.\n",
    "\n",
    "Imagine a network classifying images as cats, dogs, or birds. The softmax function would convert the network's outputs for each class into probabilities (e.g., 0.8 for cat, 0.1 for dog, and 0.1 for bird). This indicates a high confidence (80%) in predicting the image as a cat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f085ea4-b2f6-4bfe-9106-afa7db0856d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Question 6\n",
    "\n",
    "Forward propagation calculates the output for a given input, but it doesn't tell us how well the network is performing. This is where backward propagation comes in.\n",
    "\n",
    "- Error Calculation: Backward propagation calculates the error (difference between the predicted output and the actual target value) for each layer, starting from the output layer and moving backward through the network.\n",
    "\n",
    "- Weight Adjustment: The errors are then used to adjust the weights and biases in a way that minimizes the overall error. This essentially fine-tunes the network's connections to improve its future predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b999401-059d-4372-a043-9ea42318b11a",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "1. Error at Output: We calculate the difference between the actual output (y) and the desired target value (t).\n",
    "\n",
    "2. Error Gradient: We calculate the derivative of the error with respect to the weighted sum (z) using the derivative of the activation function applied at the output.\n",
    "\n",
    "3. Weight Update: We use the error gradient and a learning rate (η) to update the weights (W) and bias (b) in a way that reduces the error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbee35-24a6-4ade-869d-5c9d973bad56",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "The chain rule is a fundamental concept in calculus that allows us to differentiate composite functions (functions within functions). In backpropagation for multi-layer neural networks:\n",
    "\n",
    "Each neuron's activation depends on the activations of the previous layer's neurons.\n",
    "We need to calculate the gradients (rates of change) of the error with respect to the weights in all layers.\n",
    "The chain rule provides a systematic way to \"backpropagate\" the error through the network, considering how each layer's activation contributes to the overall error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec32490-70fe-432d-a12c-5969c73a86e7",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "Here are some common challenges that can arise during backward propagation in neural networks, along with strategies to address them:\n",
    "\n",
    "**1. Vanishing or Exploding Gradients:**\n",
    "\n",
    "- **Problem:** During backpropagation, the gradients used to update weights can become very small (vanishing) or very large (exploding) as they propagate through the network, especially in deep architectures. This can make learning slow or prevent it altogether.\n",
    "- **Solutions:**\n",
    "    - **Xavier/He initialization:** Initialize weights based on the number of input and output neurons in a layer to ensure gradients have a reasonable starting magnitude.\n",
    "    - **Gradient clipping:** Limit the maximum value of gradients to prevent them from exploding.\n",
    "    - **Residual connections (ResNets):** Introduce direct connections between layers (skip connections) to allow gradients to flow more easily through the network.\n",
    "\n",
    "**2. Local Minima:**\n",
    "\n",
    "- **Problem:** The optimization algorithm might get stuck in a local minimum, where the error is lower than its immediate surroundings but not the global minimum. This can lead to suboptimal performance.\n",
    "- **Solutions:**\n",
    "    - **Momentum:** Use momentum to incorporate the direction of previous gradient updates, helping to escape local minima.\n",
    "    - **Learning rate scheduling:** Adjust the learning rate during training to control the size of steps taken towards the minimum.\n",
    "    - **Early stopping:** Stop training if the validation error plateaus for a certain number of epochs to avoid overfitting to the training data.\n",
    "\n",
    "**3. Overfitting:**\n",
    "\n",
    "- **Problem:** The model performs well on the training data but fails to generalize to unseen data. This happens when the network learns the training data's noise instead of the underlying patterns.\n",
    "- **Solutions:**\n",
    "    - **L1/L2 regularization:** Add penalty terms to the loss function that encourage smaller weights, reducing model complexity and preventing overfitting.\n",
    "    - **Dropout:** Randomly drop out a certain percentage of neurons during training, forcing the network to learn more robust features.\n",
    "    - **Data augmentation:** Artificially create new training data examples by applying random transformations (e.g., rotations, flips) to existing data, increasing the diversity of training examples.\n",
    "\n",
    "**4. Computational Cost:**\n",
    "\n",
    "- **Problem:** Backpropagation can be computationally expensive, especially for large datasets or complex models.\n",
    "- **Solutions:**\n",
    "    - **Batching:** Train the network on mini-batches of data instead of the entire dataset at once, improving memory efficiency and potentially speeding up training.\n",
    "    - **Gradient accumulation:** Accumulate gradients for multiple mini-batches before updating weights, reducing the number of parameter updates and potentially speeding up training.\n",
    "    - **Parallelization:** Train the network on multiple GPUs or TPUs to distribute the computational load and accelerate training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f087c7-a454-4155-9319-853006e23bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
