{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de92563-5236-408b-b109-6dd85f3ad36b",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    " The relationship between polynomial functions and kernel functions in machine learning algorithms, particularly in Support Vector Machines (SVMs), is that polynomial functions can be used as kernel functions to transform data into higher-dimensional spaces. Kernel functions are mathematical functions that compute the similarity (or inner product) between data points in the input space or in a higher-dimensional feature space. Polynomial kernel functions are a type of kernel function used to capture nonlinear relationships in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ef435f-14b1-44de-8331-abb9b5412042",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "By passing the kernel parameter as polynomial in the SVC initialization :\n",
    "\n",
    "SVC( kernel = \"polynomial\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdd07b-07a1-401d-a7f4-8723da80bcf0",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "As you increase the value of epsilon, it generally leads to a larger number of support vectors, as more data points can fall within the wider tube without causing a penalty. In contrast, smaller values of epsilon make the tube narrower and result in fewer support vectors, as only data points very close to the regression line are considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4a76b-0d3c-4de5-9140-9c3f99390961",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "1. **Kernel Function**: The choice of kernel function (linear, poly, rbf, etc.) determines the type of nonlinearity that SVR can capture. Different kernels are suited to different types of data distributions. For example, the poly kernel is suitable for polynomial relationships, while the rbf kernel captures more complex, nonlinear patterns.\n",
    "\n",
    "2. **C Parameter**: The C parameter controls the trade-off between minimizing the training error and maximizing the margin. Smaller C values result in larger margins but may allow some training errors, while larger C values prioritize minimizing training errors but may lead to overfitting. Adjusting C impacts the balance between bias and variance.\n",
    "\n",
    "3. **Epsilon Parameter**: The epsilon parameter defines the width of the Îµ-insensitive tube. Increasing epsilon allows more training points to be within the tube without contributing to the loss function, leading to a wider margin. Smaller epsilon values result in a narrower tube and a smaller margin.\n",
    "\n",
    "4. **Gamma Paramete**: The gamma parameter affects the shape of the decision boundary. Higher gamma values make the decision boundary more sensitive to individual data points, potentially leading to overfitting. Lower gamma values result in smoother decision boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b5215ab-9088-4beb-90fd-074236af4df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Best Hyperparameters: {'C': 1, 'gamma': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svm_classifier.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Question 5\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load the dataset (e.g., the Iris dataset)\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "classifier = SVC()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the classifier (accuracy)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Tune hyperparameters using GridSearchCV (example with C and gamma)\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "tuned_classifier = SVC(**best_params)\n",
    "tuned_classifier.fit(X, y)\n",
    "\n",
    "# Save the trained classifier to a file (e.g., 'svm_classifier.pkl') for future use\n",
    "joblib.dump(tuned_classifier, 'svm_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ccf0e2-1848-4d02-857e-f2308cc2d717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
