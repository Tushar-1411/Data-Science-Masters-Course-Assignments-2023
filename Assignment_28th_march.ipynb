{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e23477f-db49-48b8-81f4-8d0007160a85",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "In OLS Regression, the goal is to minimize the sum of squared residuals between the observed and predicted values. However, in the presence of multicollinearity, the estimates of the regression coefficients can become unstable or biased.\n",
    "\n",
    "Ridge Regression adds a penalty term to the OLS objective function, which includes the sum of squared coefficients (L2 norm) multiplied by a hyperparameter lambda (λ). This penalty helps in shrinking the coefficients towards zero, reducing the impact of multicollinearity and preventing overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb3f1a-0696-4fc4-8250-4b5bf0ceb350",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Ridge Regression makes similar assumptions to those of linear regression, including:\n",
    "\n",
    "1. Linearity: The relationship between the predictor variables and the response variable is assumed to be linear.\n",
    "\n",
    "2. Independence: Residuals should be independent of each other.\n",
    "\n",
    "3. Homoscedasticity: Residuals should have constant variance (homoscedasticity).\n",
    "\n",
    "4. Normality: Residuals should be normally distributed.\n",
    "\n",
    "However, Ridge Regression is more robust to violations of the assumption of multicollinearity compared to ordinary linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fe0bfb-d949-4d80-800f-f3a75427ae17",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "The tuning parameter λ (lambda) controls the amount of regularization applied in Ridge Regression. The value of λ determines the degree of shrinkage of the coefficients. To select an appropriate value of λ, techniques such as cross-validation are commonly used. Cross-validation involves splitting the dataset into training and validation subsets, then evaluating the model's performance for different values of λ. The value of λ that results in the best performance on the validation set is chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531728a2-acf1-4277-96fd-2d4abe2d42f4",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Ridge Regression is not typically used for feature selection in the same way as techniques like Lasso Regression. While Ridge Regression does shrink coefficients towards zero, it rarely sets them exactly to zero. This means that Ridge Regression will retain all the features but will reduce their impact on the model if they are less important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836183c-65a5-4841-b44a-3d5b3796aa96",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "When multicollinearity is present, the coefficient estimates in Ridge Regression are biased but have lower variance. This bias-variance trade-off often results in better overall predictive performance, even though the individual coefficient estimates may not precisely reflect the true relationships between predictors and the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc87b25-91e4-4e64-82d6-5561e4ee7e31",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Ridge Regression can handle both categorical and continuous independent variables. However, categorical variables need to be properly encoded before being included in the model. Categorical variables with two levels (binary variables) can be directly included, while categorical variables with more than two levels need to be one-hot encoded or converted into dummy variables. This process creates a set of binary (0/1) variables that represent the presence or absence of each category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530ed0ac-2b39-45f1-a59f-1563f9113c42",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Interpreting coefficients in Ridge Regression is similar to interpreting coefficients in ordinary linear regression. However, due to the regularization term, the coefficients are shrunk towards zero, which affects their magnitudes. Here's a general guideline:\n",
    "\n",
    "- A positive coefficient indicates a positive relationship between the predictor and the response variable. For example, a one-unit increase in the predictor is associated with an increase in the response.\n",
    "\n",
    "- A negative coefficient indicates a negative relationship between the predictor and the response variable. A one-unit increase in the predictor is associated with a decrease in the response.\n",
    "\n",
    "- The magnitude of the coefficient indicates the strength of the relationship. Larger magnitudes imply a stronger impact on the response.\n",
    "\n",
    "Keep in mind that Ridge Regression tends to shrink coefficients, so the interpretation is focused on the direction and relative importance of predictors rather than their precise values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332988f-ca3d-44ae-96dd-112cf4c89897",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Ridge Regression can be used for time-series data analysis, although it's not the most common choice. Time-series data often have temporal dependencies that Ridge Regression doesn't inherently capture. Techniques like autoregressive integrated moving average (ARIMA), seasonal decomposition, or more advanced methods like state space models or recurrent neural networks (RNNs) are often preferred for time-series analysis.\n",
    "\n",
    "However, Ridge Regression can be adapted for time-series data if you engineer appropriate features that capture temporal patterns or lag effects. For example, you could include lagged values of the target variable or other relevant variables as predictors. Nonetheless, more specialized techniques like ARIMA or RNNs are usually better suited for handling the unique characteristics of time-series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b7947-527f-45b1-8929-d6eb72bac930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
